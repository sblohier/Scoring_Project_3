{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour simplifier les unités de monnaie seront les euros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package pour les expressions régulières\n",
    "import re\n",
    "\n",
    "# Package pour la gestion des objets json\n",
    "import json\n",
    "\n",
    "# Package manipuler les fichiers et répertoires\n",
    "import os\n",
    "\n",
    "# Package pour les tableaux et dataframe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.errors import MergeError\n",
    "\n",
    "# Package pour analyse statistique\n",
    "import scipy.stats as ss\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "# Package pour la visualisation graphique\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import seaborn as sns\n",
    "\n",
    "# Typing des fonctions\n",
    "from typing import List\n",
    "\n",
    "# Packages scikit-learn pour modélisation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import (\n",
    "    OneHotEncoder, OrdinalEncoder, LabelEncoder,\n",
    "    RobustScaler, StandardScaler\n",
    ")\n",
    "from scikitplot.metrics import plot_cumulative_gain\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_predict, cross_val_score\n",
    ")\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.feature_selection import VarianceThreshold, RFECV\n",
    "from boruta import BorutaPy\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from  xgboost import XGBClassifier\n",
    "from sklearn.calibration import (\n",
    "    CalibratedClassifierCV,\n",
    "    calibration_curve\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.inspection import permutation_importance\n",
    "from shap import (\n",
    "    TreeExplainer, summary_plot, \n",
    "    KernelExplainer,Explainer\n",
    ")\n",
    "\n",
    "from sklearn import set_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None #  pour afficher toutes les colonnes de la base\n",
    "pd.options.display.max_rows = None  # pour afficher toutes les lignes de la base\n",
    "pd.set_option('display.max_colwidth', None) # on ne définit pas de largeur max des colonnes afin d'éviter de tronquer leur contenu à l'affichage\n",
    "set_config(display='diagram') # pour afficher la visualisation graphique des données ou des processus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1240,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Importation et merge des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on va tester 4 grandes familles de modèle\n",
    "* logistique régression\n",
    "* SVC\n",
    "* RandomForest\n",
    "* XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1223,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_ordinal_cols = []\n",
    "cat_one_hot_encoder = []\n",
    "\n",
    "for i,var in enumerate(cat_cols) : \n",
    "    if all(isinstance(var, (int, float)) for var in X_train[var]) : \n",
    "        cat_ordinal_cols.append(var)\n",
    "    else :\n",
    "        cat_one_hot_encoder.append(var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Pipeline de transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialisation des Imputers\n",
    "num_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "cat_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "# Initialisation des encoders\n",
    "ordinal_encoder = OrdinalEncoder(categories= [[\"No\", \"Yes\"],[\"No\", \"Yes\"],[\"No\", \"Yes\"],[\"No\", \"Yes\"],[\"No\", \"Yes\"],[\"No\", \"Yes\"]])  # SLOSLOà tester pour être sure\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "# Standard scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "#make pipeline\n",
    "cat_ordinal_transformer = make_pipeline( cat_imputer, ordinal_encoder)\n",
    "cat_one_hot_encoder_transformer = make_pipeline( cat_imputer, one_hot_encoder)\n",
    "cat_other_transformer = make_pipeline( cat_imputer)\n",
    "num_transformer = make_pipeline( num_imputer, scaler )\n",
    "# Définition du préprocesseur\n",
    "preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat_ord\", cat_ordinal_transformer, bool_cols),\n",
    "             (\"cat_oh\", cat_one_hot_encoder_transformer, cat_one_hot_encoder),\n",
    "             (\"cat_\", cat_other_transformer, cat_ordinal_cols),\n",
    "             (\"numerical\", num_transformer, num_cols)            \n",
    "        ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Définition des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1225,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_models  = { \"Logistique Régression\" :  LogisticRegression(max_iter = 1000, random_state= seed), \n",
    "               \"SVC Linéaire\" : SVC(kernel='linear', random_state=seed),\n",
    "              # \"Nearest Neighbors\" : KNeighborsClassifier(n_jobs= -1),\n",
    "               \"XGBboost\" : XGBClassifier(random_state =42),\n",
    "               \"Random Forest\" : RandomForestClassifier(random_state=42)\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1226,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Selected columns, ['family_size_bins', 'number_of_referrals_bins', 'family_size_bins', 'number_of_referrals_bins', 'contract', 'offer', 'payment_method', 'internet_type', 'total_of_services_add', 'total_of_services_add', 'tenure_in_months_bins', 'tenure_in_months_bins'], are not unique in dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1226], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m      4\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessor\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[1;32m      5\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregressor\u001b[39m\u001b[38;5;124m'\u001b[39m, clf_models[model])])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#print(pipe)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#display(pipe)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Entrainement du modèle à l'aide de (X_train, y_train), et prédiction de y_train_pred\u001b[39;00m\n\u001b[1;32m     12\u001b[0m roc_auc \u001b[38;5;241m=\u001b[39m cross_val_score(pipe,X_train, y_train,cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring \u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/FORMATION_DATA_SCIENTIST/Scoring_Project_3/env_scoring/lib/python3.10/site-packages/sklearn/pipeline.py:390\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    389\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m--> 390\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/FORMATION_DATA_SCIENTIST/Scoring_Project_3/env_scoring/lib/python3.10/site-packages/sklearn/pipeline.py:348\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    346\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    347\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params_steps\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/Documents/FORMATION_DATA_SCIENTIST/Scoring_Project_3/env_scoring/lib/python3.10/site-packages/joblib/memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/FORMATION_DATA_SCIENTIST/Scoring_Project_3/env_scoring/lib/python3.10/site-packages/sklearn/pipeline.py:893\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 893\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    895\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/Documents/FORMATION_DATA_SCIENTIST/Scoring_Project_3/env_scoring/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:672\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformers()\n\u001b[0;32m--> 672\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_column_callables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[1;32m    675\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(X, y, _fit_transform_one)\n",
      "File \u001b[0;32m~/Documents/FORMATION_DATA_SCIENTIST/Scoring_Project_3/env_scoring/lib/python3.10/site-packages/sklearn/compose/_column_transformer.py:352\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    350\u001b[0m         columns \u001b[38;5;241m=\u001b[39m columns(X)\n\u001b[1;32m    351\u001b[0m     all_columns\u001b[38;5;241m.\u001b[39mappend(columns)\n\u001b[0;32m--> 352\u001b[0m     transformer_to_input_indices[name] \u001b[38;5;241m=\u001b[39m \u001b[43m_get_column_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m all_columns\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices \u001b[38;5;241m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[0;32m~/Documents/FORMATION_DATA_SCIENTIST/Scoring_Project_3/env_scoring/lib/python3.10/site-packages/sklearn/utils/__init__.py:435\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[0;34m(X, key)\u001b[0m\n\u001b[1;32m    433\u001b[0m         col_idx \u001b[38;5;241m=\u001b[39m all_columns\u001b[38;5;241m.\u001b[39mget_loc(col)\n\u001b[1;32m    434\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col_idx, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n\u001b[0;32m--> 435\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    436\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSelected columns, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, are not unique in dataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    437\u001b[0m             )\n\u001b[1;32m    438\u001b[0m         column_indices\u001b[38;5;241m.\u001b[39mappend(col_idx)\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mValueError\u001b[0m: Selected columns, ['family_size_bins', 'number_of_referrals_bins', 'family_size_bins', 'number_of_referrals_bins', 'contract', 'offer', 'payment_method', 'internet_type', 'total_of_services_add', 'total_of_services_add', 'tenure_in_months_bins', 'tenure_in_months_bins'], are not unique in dataframe"
     ]
    }
   ],
   "source": [
    "for model in clf_models : \n",
    "        # Définition du pipeline de transformation pipe_mod1_ord_enc\n",
    "        pipe = Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('regressor', clf_models[model])])\n",
    "        #print(pipe)\n",
    "        pipe.fit(X_train, y_train)\n",
    "        #display(pipe)\n",
    "\n",
    "\n",
    "        # Entrainement du modèle à l'aide de (X_train, y_train), et prédiction de y_train_pred\n",
    "        roc_auc = cross_val_score(pipe,X_train, y_train,cv=3, n_jobs=-1, scoring ='roc_auc')\n",
    "        print(f\"Modele {model} : Score Val roc_auc : {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1 Régression logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1.1 avec GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paramètres suivants sur lesqeul j'ai envie de jouer :\n",
    "regarder en même temps le temps CPU\n",
    "\n",
    "solver = {new-cholesky : L2, None\n",
    "          liblinear  : {L1, L2}\n",
    "          lbfgs : {l2, None}}\n",
    "\n",
    "C = [0.1, 1, 10, 100]\n",
    "\n",
    "tol = 1e-5, 1e-4, 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pipe_lr = Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('classifier', LogisticRegression(max_iter = 1000, random_state= seed))]) #\n",
    "    \n",
    "grid = {\"classifier__solver\" : [\"lbfgs\", \"liblinear\"],\n",
    "        \"classifier__penalty\" : [\"l2\"],\n",
    "                \"classifier__C\" : [0.1, 1, 5 ,10, 100],\n",
    "                \"classifier__tol\" : [0.0001, 0.001,0.01,0.1]}\n",
    "        \n",
    "grid_search = GridSearchCV(estimator = pipe_lr, param_grid = grid, cv = 5, n_jobs = 5, return_train_score = True, scoring = \"roc_auc\")\n",
    "grid_search.fit(X_train, y_train)  \n",
    "result_lr_gs = pd.DataFrame(grid_search.cv_results_).sort_values(\"mean_test_score\", ascending = False)\n",
    "print(f\"Pour la Regression Logistique avec Grid Search : \\nles meilleurs params : {grid_search.best_params_}\\nle meilleur score : {grid_search.best_score_}\")\n",
    "result_lr_gs[[\"params\",\"mean_test_score\",\"mean_train_score\"]].head()\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1.2 avec RandomizedSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.1.3 Hyperparamètres retenus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les parametre retenus ont dans le gridsearch \n",
    "* C*=0.2941\n",
    "* PENALTY = L2\n",
    "* SOLVER =LIBLINEAR\n",
    "* TOL=0.02962\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2 SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2.1 avec GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "pipe_svc = Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('classifier', SVC(kernel='linear', random_state=seed, max_iter=1000))]) #\n",
    "    \n",
    "grid_svc = { \"classifier__C\" : [0.1, 1, 5 ,10, 100],\n",
    "\"classifier__class_weight\" : [\"balanced\", \"none\"],\n",
    "                \"classifier__tol\" : [0.0001, 0.001,0.01,0.1]}\n",
    "        \n",
    "grid_search_svc = GridSearchCV(estimator = pipe_svc, param_grid = grid_svc, cv = 5,n_jobs = 5, return_train_score = True, scoring = \"roc_auc\")\n",
    "grid_search_svc.fit(X_train, y_train)   \n",
    "\n",
    "result_svc_gs = pd.DataFrame(grid_search_svc.cv_results_).sort_values(\"mean_test_score\", ascending = False)\n",
    "print(f\"Pour la SVC avec Grid Search : \\nles meilleurs params : {grid_search_svc.best_params_}\\nle meilleur score : {grid_search_svc.best_score_}\")\n",
    "result_svc_gs[[\"params\",\"mean_test_score\",\"mean_train_score\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2.2 avec RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_random = {\"classifier__class_weight\" : [\"balanced\", \"none\"],\n",
    "                \"classifier__C\" : loguniform(0.01, 100),\n",
    "                \"classifier__tol\" : loguniform(0.00001,0.11)}\n",
    "\n",
    "        \n",
    "grid_rs_svc = RandomizedSearchCV(estimator = pipe_svc, param_distributions= grid_random, cv = 5, n_jobs = 5,n_iter=200,return_train_score = True, scoring = \"roc_auc\")\n",
    "grid_rs_svc.fit(X_train, y_train)   \n",
    "result_svc_rs = pd.DataFrame(grid_rs_svc.cv_results_).sort_values(\"mean_test_score\", ascending = False)\n",
    "print(f\"Pour la SVC avec Random Search : \\nles meilleurs params : {grid_rs_svc.best_params_}\\nle meilleur score : {grid_rs_svc.best_score_}\")\n",
    "result_svc_rs[[\"params\",\"mean_test_score\",\"mean_train_score\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.2.3 Hyperparamètres retenus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametre retenu :\n",
    "grid seach\n",
    "{'classifier__C': 0.1, 'classifier__class_weight': 'balanced', 'classifier__tol': 0.0001}\t0.882455\t0.886631"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3 Forêt aléatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.3.1 avec GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('classifier', RandomForestClassifier(random_state=42))]) #\n",
    "    \n",
    "grid = { \"classifier__n_estimators\" : [100, 200, 500, 1000],\n",
    "\"classifier__max_depth\" : [3,4,5,6]}\n",
    "        \n",
    "grid_search_rf = GridSearchCV(estimator = pipe_rf, param_grid = grid, cv = 5,n_jobs = 5, return_train_score = True, scoring = \"roc_auc\")\n",
    "grid_search_rf.fit(X_train, y_train)   \n",
    "result_rf_gs = pd.DataFrame(grid_search_rf.cv_results_).sort_values(\"mean_test_score\", ascending = False)\n",
    "print(f\"Pour la rf avec grid search : \\nles meilleurs params : {grid_search_rf.best_params_}\\nle meilleur score : {grid_search_rf.best_score_}\")\n",
    "result_rf_gs[[\"params\",\"mean_test_score\",\"mean_train_score\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.3.2 avec RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_random = {\"classifier__max_depth\" : range(3,7,1),\n",
    "                \"classifier__n_estimators\" : range(100,600,50)}\n",
    "\n",
    "        \n",
    "grid_rs_rf = RandomizedSearchCV(estimator = pipe_rf, param_distributions= grid_random, cv = 5, n_jobs = 5,n_iter=80,return_train_score = True, scoring = \"roc_auc\")\n",
    "grid_rs_rf.fit(X_train, y_train)   \n",
    "result_rf_rs = pd.DataFrame(grid_rs_rf.cv_results_).sort_values(\"mean_test_score\", ascending = False)\n",
    "print(f\"Pour la rf avec Random Search : \\nles meilleurs params : {grid_rs_rf.best_params_}\\nle meilleur score : {grid_rs_rf.best_score_}\")\n",
    "result_rf_rs[[\"params\",\"mean_test_score\",\"mean_train_score\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.3.3 Hyperparamètres retenus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{'classifier__max_depth': 6, 'classifier__n_estimators': 200}\t0.886168\t0.908774\n",
    "\n",
    "{'classifier__n_estimators': 400, 'classifier__max_depth': 6}\t0.886262\t0.908853"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.4 Modèle XgBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.4.1 avec GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_xgb = Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('classifier', XGBClassifier( objective= 'binary:logistic',random_state =42))]) #\n",
    "    \n",
    "grid = { \"classifier__n_estimators\" : [100,200,500],\n",
    "\"classifier__max_depth\" : [3,4,5,6],\n",
    "                \"classifier__eta\" : [0.01,0.05,0.1],\"classifier__lambda\" : [0.1,1,10]}\n",
    "        \n",
    "grid_search_xgb = GridSearchCV(estimator = pipe_xgb, param_grid = grid, cv = 5,n_jobs = 5, return_train_score = True, scoring = \"roc_auc\")\n",
    "grid_search_xgb.fit(X_train, y_train)   \n",
    "\n",
    "result_gs_xgb = pd.DataFrame(grid_search_xgb.cv_results_).sort_values(\"mean_test_score\", ascending = False)\n",
    "print(f\"Pour le xsb avec grid Search : \\nles meilleurs params : {grid_search_xgb.best_params_}\\nle meilleur score : {grid_search_xgb.best_score_}\")\n",
    "result_gs_xgb[[\"params\",\"mean_test_score\",\"mean_train_score\"]].head()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.4.2 avec RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "gri_random = {\"classifier__n_estimators\" : range(100,600,50),\n",
    "                \"classifier__max_depth\" : range(3,7,1),\n",
    "                \"classifier__eta\" : loguniform(0.01,0.3),\n",
    "                 \"classifier__lambda\" : loguniform(0.1,10)}\n",
    "        \n",
    "grid_rs_xgb = RandomizedSearchCV(estimator = pipe_xgb, param_distributions= gri_random, cv = 5, n_jobs = 5, n_iter=144,return_train_score = True, scoring = \"roc_auc\")\n",
    "grid_rs_xgb.fit(X_train, y_train)   \n",
    "\n",
    "result_rs_xgb = pd.DataFrame(grid_rs_xgb.cv_results_).sort_values(\"mean_test_score\", ascending = False)\n",
    "print(f\"Pour le xgb avec rs Search : \\nles meilleurs params : {grid_rs_xgb.best_params_}\\nle meilleur score : {grid_rs_xgb.best_score_}\")\n",
    "result_rs_xgb[[\"params\",\"mean_test_score\",\"mean_train_score\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.3.4.3 Hyperparamètres retenus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gs :\n",
    "{'classifier__eta': 0.01, 'classifier__lambda': 1, 'classifier__max_depth': 4, 'classifier__n_estimators': 500}\t0.898699\t0.923246\n",
    "\n",
    "\n",
    "rs \n",
    "{'classifier__eta': 0.03962445310841409, 'classifier__lambda': 4.5245010993028485, 'classifier__max_depth': 4, 'classifier__n_estimators': 150}\t0.898761\t0.922564"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Chargez la fonction de calcul du score de Spiegelhalter\n",
    "def score_spiegelhalter(y_true, y_pred):\n",
    "    numerateur = np.sum(np.multiply(y_true - y_pred, 1 - 2 * y_pred))\n",
    "    denominateur = np.sqrt(\n",
    "        np.sum(\n",
    "            np.multiply(\n",
    "                np.multiply(np.power(1 - 2 * y_pred, 2), y_pred), 1 - y_pred\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return numerateur / denominateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_models  = { \"Logistique Régression\" :  LogisticRegression(max_iter = 1000, random_state= seed,C=2941, penalty=\"l2\", solver = 'liblinear', tol = 0.02962  ), \n",
    "               \"SVC Linéaire\" : SVC(kernel='linear', probability=True,random_state=seed, C = 0.1, class_weight=\"balanced\", tol = 0.0001),\n",
    "               \"Random Forest\" : RandomForestClassifier(random_state=42, n_estimators=400, max_depth=6),\n",
    "               \"XGBboost\" : XGBClassifier(random_state =42,reg_lambda = 1, eta = 0.01, max_depth = 4, n_estimators = 500)\n",
    "               }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in clf_models : \n",
    "        # Définition du pipeline de transformation pipe_mod1_ord_enc\n",
    "        pipe = Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('regressor', clf_models[model])])\n",
    "        #print(pipe)\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_train_proba = pipe.predict_proba(X_train )\n",
    "        y_test_proba = pipe.predict_proba(X_test)\n",
    "        auc_train = roc_auc_score(y_train, y_train_proba[:,1])\n",
    "        auc_test = roc_auc_score(y_test, y_test_proba[:,1])\n",
    "        ## enregister ici les résultt\n",
    "\n",
    "        # # Entrainement du modèle à l'aide de (X_train, y_train), et prédiction de y_train_pred\n",
    "        print(f\"Modele {model} : Train  : {auc_train}, Test : {auc_test}\")\n",
    "\n",
    "        print(f\"SPH avant calibration: {score_spiegelhalter(y_test, y_test_proba[:,1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les 4 modeles présentent de très bons résultats, ils sont robustes tous les 4 on peut utiliser le XGBboost par la suite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.1 Courbe de Lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(5,4))\n",
    "plot_cumulative_gain(y_test, y_test_proba, title='Courbe de Lift', ax=ax1,  title_fontsize='13', text_fontsize='10')\n",
    "\n",
    "# x10 = 0.1\n",
    "# ypos = y_test.index(x10)\n",
    "# y10 = y_test_proba[ypos]\n",
    "\n",
    "# #Labeling the graph (ymax+1 is defining the distance from the word to the point)   \n",
    "# ax1.annotate('l0.1', xy=(x10, y10), xytext=(x10,y10 ))\n",
    "\n",
    "\n",
    "\n",
    "ax1.set_xlabel(str(\"Moyenne des probabilités\"))\n",
    "ax1.set_ylabel(f'y_pred > 0 _ nbins = {j}')\n",
    "ax1.grid(visible=True, which='major', axis='y')\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['bottom'].set_visible(True)\n",
    "ax1.spines['left'].set_visible(False)\n",
    "del ax1.lines[0]                 # delete the desired class plot\n",
    "#ax1.lines[1].set_color(\"red\")\n",
    "ax1.lines[0].set_linewidth(1),ax1.lines[1].set_linewidth(1)\n",
    "ax1.lines[0].set_color(\"blue\")\n",
    "#ax1.set_xticks(range(0,1,0.1))\n",
    "ax1.legend().set_visible(False)  # hide the legend\n",
    "ax1.legend().get_texts()[0].set_text(\"Classe 1 coucou\")  # turn the legend back on\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure ci-dessus : changer les set-ticks, ajouter une ligne verticale des 5%, 10%, 15%, 20, 25%\n",
    "voir si stop la courbe et la refaire ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4.2 Calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.2.1 Séparation du jeu de test en calibrated et test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cal, X_test_cal, y_cal, y_test_cal = train_test_split(X_test, y_test, test_size= 0.5, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_cal_proba_before_calibration = pipe.predict_proba(X_test_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPH = score_spiegelhalter(y_test_cal, y_test_cal_proba_before_calibration[:,1])\n",
    "SPH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.2.1 Courbe de Calibration - avant calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Chargez la fonction de calcul de la courbe de calibration via sklearn\n",
    "def sklearn_calibration(y_true, y_pred, n_bins=20):\n",
    "\n",
    "    prob_true, prob_pred = calibration_curve(\n",
    "        y_true, y_pred,\n",
    "        n_bins=n_bins,\n",
    "        strategy=\"quantile\"\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame({\"prob_pred\":prob_pred, \"prob_true\":prob_true})\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Définition de la palette et de la légende pour le type de carburant\n",
    "#palette = {\"GAZOIL\" : \"orange\", \"ESSENCE\" : \"green\", \"AUTRE\" : \"grey\"}\n",
    "#handle_ = [plt.Line2D([], [], color=col, marker='o', linestyle='', markersize=8, alpha=0.5) for col in palette.values()]\n",
    "#legend_  = [carburant for carburant in palette.keys()]\n",
    "\n",
    "#0. Création de la figure\n",
    "fig, axe = plt.subplots(figsize=(5,5), constrained_layout=True)\n",
    "\n",
    "\n",
    "# Itération sur les 6 variables\n",
    "j = 20#for i, j in enumerate(range(5,20,5)) :\n",
    "sklearn_calibration_df = sklearn_calibration(y_test, y_test_proba[:,1], 20)#1. Création du scatterplot\n",
    "sns.scatterplot(ax=axe, data=sklearn_calibration_df, x = 'prob_pred', y=\"prob_true\")#,palette = palette, legend = False)\n",
    "# sur le scatterplot coé = f(conso_mixte) on rajoute les 3 droites suivantes :\n",
    "sns.lineplot(ax=axe,  x = [0, 1], y=[0,1],alpha=0.5)#, color=palette[\"ESSENCE\"])\n",
    "\n",
    "#2. Gestion des axis et labels\n",
    "axe.set_xlabel(str(\"Moyenne des probabilités\"))\n",
    "axe.set_ylabel(f'y_pred > 0 _ nbins = {j}')\n",
    "# if j == 0 :\n",
    "# axe[i,j].set_ylabel('Emission CO2 (g/km)')\n",
    "\n",
    "#3. Ajout des lignes horizontales\n",
    "axe.grid(visible=True, which='major', axis='y')\n",
    "axe.spines['top'].set_visible(False)\n",
    "axe.spines['right'].set_visible(False)\n",
    "axe.spines['bottom'].set_visible(True)\n",
    "axe.spines['left'].set_visible(False)\n",
    "  \n",
    "#3. Ajout de la légende\n",
    "#0handles, labels = plt.gca().get_legend_handles_labels()\n",
    "#plt.legend(handle_, legend_, title = \"Type de carburant\", loc='center left', bbox_to_anchor= (1.04, 1), borderaxespad=0, frameon=False, fontsize = 10)\n",
    "\n",
    "#4. Ajout du titre principal\n",
    "#fig.suptitle(f'Emissions de CO2 (g/km) en fonction de la puissance maximale, de la masse, de leur ratio ainsi que des consommations en carburant en milieu urbain, extra urbain et mixte.')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Le modele est mal calibré |SH| > 2\n",
    "* Technique de calibration sur les sets : Puisque notre classifieur a déjà été entrainé, on met de coté une partie de jeu de données de test pour la calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.4.2.2 Resultat après calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciation du modèle de calibration\n",
    "\n",
    "calibration_clf = CalibratedClassifierCV(base_estimator=pipe, method='isotonic', cv=\"prefit\", n_jobs=-1)\n",
    "calibration_clf.fit(X_cal,y_cal)\n",
    "y_test_cal_proba = calibration_clf.predict_proba(X_test_cal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPH = score_spiegelhalter(y_test_cal, y_test_cal_proba[:,1])\n",
    "SPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Définition de la palette et de la légende pour le type de carburant\n",
    "#palette = {\"GAZOIL\" : \"orange\", \"ESSENCE\" : \"green\", \"AUTRE\" : \"grey\"}\n",
    "#handle_ = [plt.Line2D([], [], color=col, marker='o', linestyle='', markersize=8, alpha=0.5) for col in palette.values()]\n",
    "#legend_  = [carburant for carburant in palette.keys()]\n",
    "\n",
    "#0. Création de la figure\n",
    "fig, axe = plt.subplots( figsize=(5,5), constrained_layout=True)\n",
    "\n",
    "\n",
    "# Itération sur les 6 variables\n",
    "sns.scatterplot(ax=axe, data=sklearn_calibration_df, x = 'prob_pred', y=\"prob_true\")#,palette = palette, legend = False)\n",
    "\n",
    "#sklearn_before_calibration_df = sklearn_calibration(y_test_cal, y_test_cal_proba_before_calibration[:,1], 20)#1. Création du scatterplot\n",
    "sns.scatterplot(ax=axe, data=sklearn_calibration_df, x = 'prob_pred', y=\"prob_true\",color = \"red\")#,palette = palette, legend = False)\n",
    "sklearn_calibration_af_df = sklearn_calibration(y_test_cal, y_test_cal_proba[:,1], 20)#1. Création du scatterplot\n",
    "sns.scatterplot(ax=axe, data=sklearn_calibration_af_df, x = 'prob_pred', y=\"prob_true\",color = \"blue\")#,palette = palette, legend = False)\n",
    "\n",
    "\n",
    "\n",
    "# sur le scatterplot coé = f(conso_mixte) on rajoute les 3 droites suivantes :\n",
    "sns.lineplot(ax=axe,  x = [0, 1], y=[0,1],alpha=0.5)#, color=palette[\"ESSENCE\"])\n",
    "    \n",
    "#2. Gestion des axis et labels\n",
    "axe.set_xlabel(str(\"Moyenne des probabilités\"))\n",
    "axe.set_ylabel(f'y_pred > 0 _ nbins = {j}')\n",
    "# if j == 0 :\n",
    "#     axe[i,j].set_ylabel('Emission CO2 (g/km)')\n",
    "\n",
    "#3. Ajout des lignes horizontales\n",
    "axe.grid(visible=True, which='major', axis='y')\n",
    "axe.spines['top'].set_visible(False)\n",
    "axe.spines['right'].set_visible(False)\n",
    "axe.spines['bottom'].set_visible(True)\n",
    "axe.spines['left'].set_visible(False)\n",
    "  \n",
    "#3. Ajout de la légende\n",
    "#0handles, labels = plt.gca().get_legend_handles_labels()\n",
    "#plt.legend(handle_, legend_, title = \"Type de carburant\", loc='center left', bbox_to_anchor= (1.04, 1), borderaxespad=0, frameon=False, fontsize = 10)\n",
    "\n",
    "#4. Ajout du titre principal\n",
    "#fig.suptitle(f'Emissions de CO2 (g/km) en fonction de la puissance maximale, de la masse, de leur ratio ainsi que des consommations en carburant en milieu urbain, extra urbain et mixte.')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Explicatibilité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.1 Analyse globale selon la permutation feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_prepro = pd.DataFrame(pipe.named_steps.preprocessor.transform(X_test), columns=tot_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"################# FEATURE IMPORTANCE###################\")\n",
    "model_fi = permutation_importance(model_, X_test_prepro, y_test, scoring=\"roc_auc\", n_repeats= 30, random_state=seed)\n",
    "feature_importance= pd.DataFrame({\"names\" : tot_cols, \"importance\" : np.round(model_fi['importances_mean'],4),\n",
    "                                          \"importance_sstd\" : np.round(model_fi['importances_std'],4), })\n",
    "print(feature_importance.sort_values(by=\"importance\",ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5.2 Analyse global selon SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_prepro = pd.DataFrame(pipe.named_steps.preprocessor.transform(X_test), columns=tot_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_explainer = TreeExplainer(model = pipe.named_steps.regressor)\n",
    "shap_values = shap_explainer(X_test_prepro)\n",
    "shap.summary_plot(shap_values = shap_values, features=X_test_prepro, plot_size=(10,6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "réfléchir à comment présenter les choses et faire un Feature_importance correct\n",
    "Analyser le problème avec la calibration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grid_random = {\"classifier__solver\" : [\"lbfgs\", \"liblinear\"],\n",
    "                \"classifier__penalty\" : [\"l2\"],\n",
    "                \"classifier__C\" : loguniform(0.1, 100),\n",
    "                \"classifier__tol\" : loguniform(0.0001,0.3)}\n",
    "        \n",
    "grid_randomized = RandomizedSearchCV(estimator = pipe_lr, param_distributions= grid_random, cv = 5, n_jobs = 5, n_iter=200,return_train_score = True, scoring = \"roc_auc\")\n",
    "grid_randomized.fit(X_train, y_train)   \n",
    "\n",
    "result_lr_rs = pd.DataFrame(grid_randomized.cv_results_).sort_values(\"mean_test_score\", ascending = False)\n",
    "print(f\"Pour la Regression Logistique avec Grid Search : \\nles meilleurs params : {grid_randomized.best_params_}\\nle meilleur score : {grid_randomized.best_score_}\")\n",
    "result_lr_rs[[\"params\",\"mean_test_score\",\"mean_train_score\"]].head()\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_scoring",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
